{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2023-09-12T15:16:36.686261Z","iopub.execute_input":"2023-09-12T15:16:36.687355Z","iopub.status.idle":"2023-09-12T15:16:37.113108Z","shell.execute_reply.started":"2023-09-12T15:16:36.687318Z","shell.execute_reply":"2023-09-12T15:16:37.111893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/crossfit-games-athletes/df_2023_games_athletes_information.csv')","metadata":{"execution":{"iopub.status.busy":"2023-09-12T15:19:39.661890Z","iopub.execute_input":"2023-09-12T15:19:39.662365Z","iopub.status.idle":"2023-09-12T15:19:39.687482Z","shell.execute_reply.started":"2023-09-12T15:19:39.662326Z","shell.execute_reply":"2023-09-12T15:19:39.686608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-12T15:19:46.285657Z","iopub.execute_input":"2023-09-12T15:19:46.286114Z","iopub.status.idle":"2023-09-12T15:19:46.323369Z","shell.execute_reply.started":"2023-09-12T15:19:46.286070Z","shell.execute_reply":"2023-09-12T15:19:46.322351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Printing boolean fo potentially duplicated entries\nprint(df.duplicated())","metadata":{"execution":{"iopub.status.busy":"2023-09-12T15:24:34.167498Z","iopub.execute_input":"2023-09-12T15:24:34.167889Z","iopub.status.idle":"2023-09-12T15:24:34.182732Z","shell.execute_reply.started":"2023-09-12T15:24:34.167857Z","shell.execute_reply":"2023-09-12T15:24:34.181657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Printing the sum of potentially duplicated entries. There is no duplicates for this dataset. \nprint(df.duplicated().sum())","metadata":{"execution":{"iopub.status.busy":"2023-09-12T15:24:59.369977Z","iopub.execute_input":"2023-09-12T15:24:59.370399Z","iopub.status.idle":"2023-09-12T15:24:59.378947Z","shell.execute_reply.started":"2023-09-12T15:24:59.370367Z","shell.execute_reply":"2023-09-12T15:24:59.377812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#If there were duplicates I would use this code to remove the identified duplicated entries based on all parameters\ndf = df.drop_duplicates()\nprint(df)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T15:29:48.662904Z","iopub.execute_input":"2023-09-12T15:29:48.663257Z","iopub.status.idle":"2023-09-12T15:29:48.685975Z","shell.execute_reply.started":"2023-09-12T15:29:48.663230Z","shell.execute_reply":"2023-09-12T15:29:48.684939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking the dataframe columns\ndf.columns","metadata":{"execution":{"iopub.status.busy":"2023-09-12T15:32:29.145557Z","iopub.execute_input":"2023-09-12T15:32:29.145922Z","iopub.status.idle":"2023-09-12T15:32:29.152142Z","shell.execute_reply.started":"2023-09-12T15:32:29.145894Z","shell.execute_reply":"2023-09-12T15:32:29.151460Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking which columns I would want to keep and remove.\ndf.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T15:32:42.968040Z","iopub.execute_input":"2023-09-12T15:32:42.968393Z","iopub.status.idle":"2023-09-12T15:32:42.992501Z","shell.execute_reply.started":"2023-09-12T15:32:42.968367Z","shell.execute_reply":"2023-09-12T15:32:42.991361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#overallRank and overallScore have no values and are not important at this point so I will remove those columns.\ndf.drop(['overallRank', 'overallScore'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T15:36:51.571214Z","iopub.execute_input":"2023-09-12T15:36:51.572204Z","iopub.status.idle":"2023-09-12T15:36:51.605495Z","shell.execute_reply.started":"2023-09-12T15:36:51.572164Z","shell.execute_reply":"2023-09-12T15:36:51.604359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Overwriting the previous dataframe\ndf = df.drop(['overallRank', 'overallScore'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T15:37:16.559403Z","iopub.execute_input":"2023-09-12T15:37:16.559819Z","iopub.status.idle":"2023-09-12T15:37:16.566057Z","shell.execute_reply.started":"2023-09-12T15:37:16.559787Z","shell.execute_reply":"2023-09-12T15:37:16.564894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking the overwrite was successful\ndf.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T15:38:00.202178Z","iopub.execute_input":"2023-09-12T15:38:00.202571Z","iopub.status.idle":"2023-09-12T15:38:00.222166Z","shell.execute_reply.started":"2023-09-12T15:38:00.202540Z","shell.execute_reply":"2023-09-12T15:38:00.221389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking for any null values within the dataset.\nprint(df.isnull())","metadata":{"execution":{"iopub.status.busy":"2023-09-12T15:40:33.938049Z","iopub.execute_input":"2023-09-12T15:40:33.938412Z","iopub.status.idle":"2023-09-12T15:40:33.955070Z","shell.execute_reply.started":"2023-09-12T15:40:33.938386Z","shell.execute_reply":"2023-09-12T15:40:33.953826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#At first it looks like there is no null values but I will make sure by summating the nulls\nprint(df.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2023-09-12T15:41:54.891523Z","iopub.execute_input":"2023-09-12T15:41:54.891909Z","iopub.status.idle":"2023-09-12T15:41:54.899334Z","shell.execute_reply.started":"2023-09-12T15:41:54.891877Z","shell.execute_reply":"2023-09-12T15:41:54.898111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Since some athletes may not compete under an affilaite I can fill in the null values for affiliateId and affiliateName with none. \ndf['affiliateId'] = df['affiliateId'].fillna('None')\ndf['affiliateName'] = df['affiliateName'].fillna('None')\nprint(df)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T15:49:25.641555Z","iopub.execute_input":"2023-09-12T15:49:25.641927Z","iopub.status.idle":"2023-09-12T15:49:25.660715Z","shell.execute_reply.started":"2023-09-12T15:49:25.641897Z","shell.execute_reply":"2023-09-12T15:49:25.659634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#I will again check the summation of null values to see if some have disappeared due to to the above code\nprint(df.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2023-09-12T15:51:05.083930Z","iopub.execute_input":"2023-09-12T15:51:05.084282Z","iopub.status.idle":"2023-09-12T15:51:05.092223Z","shell.execute_reply.started":"2023-09-12T15:51:05.084255Z","shell.execute_reply":"2023-09-12T15:51:05.091188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#There is one entry that has a null value for countryOfOriginName. I will find that entry.\ndf[df['countryOfOriginName'].isna()]","metadata":{"execution":{"iopub.status.busy":"2023-09-12T15:54:51.896026Z","iopub.execute_input":"2023-09-12T15:54:51.896433Z","iopub.status.idle":"2023-09-12T15:54:51.915385Z","shell.execute_reply.started":"2023-09-12T15:54:51.896372Z","shell.execute_reply":"2023-09-12T15:54:51.914162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Since it is only one (and I could have caught this in excel before coming to pandas), I will simply look up this athlete and impute their country of origin.\ndf['countryOfOriginName'] = df['countryOfOriginName'].fillna('Russia')","metadata":{"execution":{"iopub.status.busy":"2023-09-12T15:59:38.577308Z","iopub.execute_input":"2023-09-12T15:59:38.578528Z","iopub.status.idle":"2023-09-12T15:59:38.584083Z","shell.execute_reply.started":"2023-09-12T15:59:38.578483Z","shell.execute_reply":"2023-09-12T15:59:38.582947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Again I will check if null values exist.\nprint(df.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2023-09-12T16:00:07.313406Z","iopub.execute_input":"2023-09-12T16:00:07.313869Z","iopub.status.idle":"2023-09-12T16:00:07.321721Z","shell.execute_reply.started":"2023-09-12T16:00:07.313838Z","shell.execute_reply":"2023-09-12T16:00:07.320500Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#now I am going to check dtypes\ndf.dtypes","metadata":{"execution":{"iopub.status.busy":"2023-09-12T16:01:09.960626Z","iopub.execute_input":"2023-09-12T16:01:09.961015Z","iopub.status.idle":"2023-09-12T16:01:09.968950Z","shell.execute_reply.started":"2023-09-12T16:01:09.960987Z","shell.execute_reply":"2023-09-12T16:01:09.967919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#I see height and weight are objects and go to the excel file to check this out. They are objects because they include a number and string but I notice that the heights and weights are not uniform in terms of inches/centimeters and pounds/kilograms so I want to fix this.\n","metadata":{},"execution_count":null,"outputs":[]}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}